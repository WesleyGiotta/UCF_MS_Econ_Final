
\subsection{Adjustment Function}

From a model including player actions at decision points, finding which actions positively affect a player and by how much can be estimated, see \cite{Shanahan:1984}.

The coefficients from a logistic regression are the log of the odd ratios for the variables.
$$ \text{Logit[Pr(Y=1)] = log(odds)} $$
$$ \exp[\text{log(odds)] = odds} $$
$$ \text{Pr(Y} = 1) = \frac{\text{odds}}{1+\text{odds}} $$
\begin{equation}
 \text{Pr(Y = 1)} = \frac{\exp(\beta_0 + \beta_1 x_1 + ... + \beta_K x_K)}{1 + \exp(\beta_0 + \beta_1 x_1 + ... + \beta_K x_K)}, \quad k=1,...K , 
 \end{equation}
where Y is the binary outcome variable for win(1) or loose(0); $\beta_0, \beta_1, ..., \beta_K$ are the regression coefficients; and $x_1,..., x_K$ are the mixed strategies.

% talk about the basket ball paper
% talk about dynamic programming 
% roulette

In 1961, Edward Thorp and Claude Shannon made a wearable computer that could estimate which five-slot section a ball would landed in when placed in a spinning roulette wheel, see \cite{Thorp:2017}. The idea was that they could input the current state of the spinning roulette---speed, tilt of the board, etc.---and then estimate where the ball would land from a predetermined reference point. Similarly, the adjustment function can be used to predict what the optimal strategy is in a current state. By inputing the cards that are currently in play and then simulating a thousand games with varying strategies, a logistic regression can used to predict who would win in that current state. The coefficients from this regression can be inputed into Equation (1) and evaluated at varying mixed strategies to find which combination of weights maximizes the probability of winning.



